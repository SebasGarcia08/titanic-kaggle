{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>embarked</th>\n",
       "      <th>age_group</th>\n",
       "      <th>familysz</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>19.091437</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>756 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   age     fare  sibsp  parch  pclass  sex  embarked  \\\n",
       "PassengerId                                                            \n",
       "1            22.000000   7.2500    1.0    0.0       2    1         2   \n",
       "2            38.000000  71.2833    1.0    0.0       0    0         0   \n",
       "3            26.000000   7.9250    0.0    0.0       2    0         2   \n",
       "4            35.000000  53.1000    1.0    0.0       0    0         2   \n",
       "5            35.000000   8.0500    0.0    0.0       2    1         2   \n",
       "...                ...      ...    ...    ...     ...  ...       ...   \n",
       "886          39.000000  29.1250    0.0    5.0       2    0         1   \n",
       "888          19.000000  30.0000    0.0    0.0       0    0         2   \n",
       "889          19.091437  23.4500    1.0    2.0       2    0         2   \n",
       "890          26.000000  30.0000    0.0    0.0       0    1         0   \n",
       "891          32.000000   7.7500    0.0    0.0       2    1         1   \n",
       "\n",
       "             age_group  familysz  survived  \n",
       "PassengerId                                 \n",
       "1                    4         1         0  \n",
       "2                    0         1         1  \n",
       "3                    4         1         1  \n",
       "4                    0         1         1  \n",
       "5                    0         1         0  \n",
       "...                ...       ...       ...  \n",
       "886                  0         0         0  \n",
       "888                  3         1         1  \n",
       "889                  3         0         0  \n",
       "890                  4         1         1  \n",
       "891                  0         1         0  \n",
       "\n",
       "[756 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '../data/'\n",
    "df = pd.read_csv('../data/processed/train.csv', index_col='PassengerId')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 3, 5, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "cat_dims = [df[col].nunique() for col in df.columns[4:]]\n",
    "print(cat_dims)\n",
    "cat_idxs = list(range(4, len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.583333\n",
       "1    0.416667\n",
       "Name: survived, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['survived'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complejidad 3 (30%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Desarrolle un modelo que permita obtener los valores de la variable objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534413108\n",
      "Device used : cpu\n",
      "epoch 0  | loss: 0.83448 | train_auc: 0.46237 | val_auc: 0.54022 |  0:00:00s\n",
      "epoch 1  | loss: 0.7376  | train_auc: 0.47446 | val_auc: 0.55707 |  0:00:00s\n",
      "epoch 2  | loss: 0.65959 | train_auc: 0.51665 | val_auc: 0.56105 |  0:00:00s\n",
      "epoch 3  | loss: 0.59701 | train_auc: 0.60955 | val_auc: 0.69973 |  0:00:00s\n",
      "epoch 4  | loss: 0.57807 | train_auc: 0.67045 | val_auc: 0.70217 |  0:00:00s\n",
      "epoch 5  | loss: 0.5771  | train_auc: 0.66585 | val_auc: 0.7231  |  0:00:00s\n",
      "epoch 6  | loss: 0.58472 | train_auc: 0.6701  | val_auc: 0.7279  |  0:00:01s\n",
      "epoch 7  | loss: 0.57493 | train_auc: 0.71573 | val_auc: 0.76721 |  0:00:01s\n",
      "epoch 8  | loss: 0.55263 | train_auc: 0.73805 | val_auc: 0.776   |  0:00:01s\n",
      "epoch 9  | loss: 0.52712 | train_auc: 0.73134 | val_auc: 0.77609 |  0:00:01s\n",
      "epoch 10 | loss: 0.51324 | train_auc: 0.74324 | val_auc: 0.77591 |  0:00:01s\n",
      "epoch 11 | loss: 0.5298  | train_auc: 0.75177 | val_auc: 0.78225 |  0:00:01s\n",
      "epoch 12 | loss: 0.5236  | train_auc: 0.74924 | val_auc: 0.77736 |  0:00:01s\n",
      "epoch 13 | loss: 0.50466 | train_auc: 0.74706 | val_auc: 0.78179 |  0:00:02s\n",
      "epoch 14 | loss: 0.50976 | train_auc: 0.75681 | val_auc: 0.78641 |  0:00:02s\n",
      "epoch 15 | loss: 0.48842 | train_auc: 0.76405 | val_auc: 0.78967 |  0:00:02s\n",
      "epoch 16 | loss: 0.50596 | train_auc: 0.76484 | val_auc: 0.7625  |  0:00:02s\n",
      "epoch 17 | loss: 0.47841 | train_auc: 0.76594 | val_auc: 0.77156 |  0:00:02s\n",
      "epoch 18 | loss: 0.48569 | train_auc: 0.7615  | val_auc: 0.78062 |  0:00:02s\n",
      "epoch 19 | loss: 0.48981 | train_auc: 0.75911 | val_auc: 0.78931 |  0:00:02s\n",
      "epoch 20 | loss: 0.48734 | train_auc: 0.75808 | val_auc: 0.77301 |  0:00:03s\n",
      "epoch 21 | loss: 0.49075 | train_auc: 0.7528  | val_auc: 0.77101 |  0:00:03s\n",
      "epoch 22 | loss: 0.47928 | train_auc: 0.72711 | val_auc: 0.7337  |  0:00:03s\n",
      "epoch 23 | loss: 0.48453 | train_auc: 0.71669 | val_auc: 0.70688 |  0:00:03s\n",
      "epoch 24 | loss: 0.45533 | train_auc: 0.69721 | val_auc: 0.68877 |  0:00:03s\n",
      "epoch 25 | loss: 0.45809 | train_auc: 0.69214 | val_auc: 0.67717 |  0:00:03s\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_auc = 0.78967\n",
      "Best weights from best epoch are automatically used!\n",
      "Device used : cpu\n",
      "epoch 0  | loss: 0.90911 | train_auc: 0.46898 | val_auc: 0.44162 |  0:00:00s\n",
      "epoch 1  | loss: 0.67798 | train_auc: 0.56263 | val_auc: 0.46767 |  0:00:00s\n",
      "epoch 2  | loss: 0.63465 | train_auc: 0.64547 | val_auc: 0.57149 |  0:00:00s\n",
      "epoch 3  | loss: 0.61531 | train_auc: 0.66712 | val_auc: 0.61166 |  0:00:00s\n",
      "epoch 4  | loss: 0.59284 | train_auc: 0.74382 | val_auc: 0.61831 |  0:00:00s\n",
      "epoch 5  | loss: 0.57142 | train_auc: 0.75428 | val_auc: 0.62304 |  0:00:00s\n",
      "epoch 6  | loss: 0.55812 | train_auc: 0.76406 | val_auc: 0.63151 |  0:00:00s\n",
      "epoch 7  | loss: 0.56409 | train_auc: 0.76554 | val_auc: 0.62659 |  0:00:01s\n",
      "epoch 8  | loss: 0.53341 | train_auc: 0.77379 | val_auc: 0.63242 |  0:00:01s\n",
      "epoch 9  | loss: 0.50852 | train_auc: 0.78445 | val_auc: 0.63279 |  0:00:01s\n",
      "epoch 10 | loss: 0.49205 | train_auc: 0.77926 | val_auc: 0.63479 |  0:00:01s\n",
      "epoch 11 | loss: 0.48561 | train_auc: 0.77327 | val_auc: 0.63525 |  0:00:01s\n",
      "epoch 12 | loss: 0.46698 | train_auc: 0.77587 | val_auc: 0.63443 |  0:00:01s\n",
      "epoch 13 | loss: 0.46602 | train_auc: 0.76052 | val_auc: 0.63506 |  0:00:01s\n",
      "epoch 14 | loss: 0.4641  | train_auc: 0.74413 | val_auc: 0.62887 |  0:00:01s\n",
      "epoch 15 | loss: 0.43646 | train_auc: 0.73297 | val_auc: 0.62614 |  0:00:01s\n",
      "epoch 16 | loss: 0.45676 | train_auc: 0.73184 | val_auc: 0.63388 |  0:00:02s\n",
      "epoch 17 | loss: 0.44287 | train_auc: 0.73137 | val_auc: 0.64135 |  0:00:02s\n",
      "epoch 18 | loss: 0.41851 | train_auc: 0.73393 | val_auc: 0.65911 |  0:00:02s\n",
      "epoch 19 | loss: 0.42183 | train_auc: 0.73558 | val_auc: 0.66302 |  0:00:02s\n",
      "epoch 20 | loss: 0.4139  | train_auc: 0.7422  | val_auc: 0.66931 |  0:00:02s\n",
      "epoch 21 | loss: 0.42757 | train_auc: 0.75241 | val_auc: 0.6674  |  0:00:02s\n",
      "epoch 22 | loss: 0.4074  | train_auc: 0.76579 | val_auc: 0.66903 |  0:00:02s\n",
      "epoch 23 | loss: 0.40453 | train_auc: 0.76827 | val_auc: 0.66821 |  0:00:02s\n",
      "epoch 24 | loss: 0.40367 | train_auc: 0.76408 | val_auc: 0.66129 |  0:00:02s\n",
      "epoch 25 | loss: 0.40488 | train_auc: 0.76347 | val_auc: 0.65938 |  0:00:02s\n",
      "epoch 26 | loss: 0.39776 | train_auc: 0.76533 | val_auc: 0.65938 |  0:00:03s\n",
      "epoch 27 | loss: 0.42062 | train_auc: 0.76851 | val_auc: 0.6592  |  0:00:03s\n",
      "epoch 28 | loss: 0.38837 | train_auc: 0.77388 | val_auc: 0.6612  |  0:00:03s\n",
      "epoch 29 | loss: 0.39592 | train_auc: 0.78073 | val_auc: 0.65993 |  0:00:03s\n",
      "epoch 30 | loss: 0.38905 | train_auc: 0.79317 | val_auc: 0.66393 |  0:00:03s\n",
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_auc = 0.66931\n",
      "Best weights from best epoch are automatically used!\n",
      "Device used : cpu\n",
      "epoch 0  | loss: 0.88938 | train_auc: 0.51616 | val_auc: 0.50138 |  0:00:00s\n",
      "epoch 1  | loss: 0.68281 | train_auc: 0.5421  | val_auc: 0.49475 |  0:00:00s\n",
      "epoch 2  | loss: 0.63333 | train_auc: 0.65703 | val_auc: 0.66092 |  0:00:00s\n",
      "epoch 3  | loss: 0.61736 | train_auc: 0.70433 | val_auc: 0.73821 |  0:00:00s\n",
      "epoch 4  | loss: 0.57105 | train_auc: 0.72843 | val_auc: 0.75387 |  0:00:00s\n",
      "epoch 5  | loss: 0.59068 | train_auc: 0.74372 | val_auc: 0.7792  |  0:00:00s\n",
      "epoch 6  | loss: 0.54957 | train_auc: 0.71651 | val_auc: 0.77128 |  0:00:00s\n",
      "epoch 7  | loss: 0.55557 | train_auc: 0.72342 | val_auc: 0.78012 |  0:00:00s\n",
      "epoch 8  | loss: 0.53861 | train_auc: 0.73741 | val_auc: 0.79385 |  0:00:00s\n",
      "epoch 9  | loss: 0.53149 | train_auc: 0.73206 | val_auc: 0.79882 |  0:00:01s\n",
      "epoch 10 | loss: 0.51789 | train_auc: 0.73382 | val_auc: 0.79495 |  0:00:01s\n",
      "epoch 11 | loss: 0.47841 | train_auc: 0.73974 | val_auc: 0.79854 |  0:00:01s\n",
      "epoch 12 | loss: 0.49429 | train_auc: 0.74164 | val_auc: 0.8049  |  0:00:01s\n",
      "epoch 13 | loss: 0.46889 | train_auc: 0.74488 | val_auc: 0.80536 |  0:00:01s\n",
      "epoch 14 | loss: 0.47076 | train_auc: 0.74923 | val_auc: 0.80278 |  0:00:01s\n",
      "epoch 15 | loss: 0.46345 | train_auc: 0.74588 | val_auc: 0.80628 |  0:00:01s\n",
      "epoch 16 | loss: 0.45664 | train_auc: 0.75124 | val_auc: 0.81863 |  0:00:01s\n",
      "epoch 17 | loss: 0.4441  | train_auc: 0.75024 | val_auc: 0.82249 |  0:00:01s\n",
      "epoch 18 | loss: 0.44885 | train_auc: 0.75151 | val_auc: 0.82139 |  0:00:02s\n",
      "epoch 19 | loss: 0.44444 | train_auc: 0.75784 | val_auc: 0.81669 |  0:00:02s\n",
      "epoch 20 | loss: 0.43983 | train_auc: 0.76613 | val_auc: 0.81365 |  0:00:02s\n",
      "epoch 21 | loss: 0.44073 | train_auc: 0.77204 | val_auc: 0.8213  |  0:00:02s\n",
      "epoch 22 | loss: 0.424   | train_auc: 0.76855 | val_auc: 0.83382 |  0:00:02s\n",
      "epoch 23 | loss: 0.41026 | train_auc: 0.76918 | val_auc: 0.82903 |  0:00:02s\n",
      "epoch 24 | loss: 0.41033 | train_auc: 0.76501 | val_auc: 0.82793 |  0:00:02s\n",
      "epoch 25 | loss: 0.41804 | train_auc: 0.78359 | val_auc: 0.82627 |  0:00:02s\n",
      "epoch 26 | loss: 0.42172 | train_auc: 0.80119 | val_auc: 0.84304 |  0:00:02s\n",
      "epoch 27 | loss: 0.40043 | train_auc: 0.8083  | val_auc: 0.85676 |  0:00:02s\n",
      "epoch 28 | loss: 0.41885 | train_auc: 0.8094  | val_auc: 0.86579 |  0:00:03s\n",
      "epoch 29 | loss: 0.40923 | train_auc: 0.80598 | val_auc: 0.86496 |  0:00:03s\n",
      "epoch 30 | loss: 0.39962 | train_auc: 0.80264 | val_auc: 0.8633  |  0:00:03s\n",
      "epoch 31 | loss: 0.38981 | train_auc: 0.80317 | val_auc: 0.85695 |  0:00:03s\n",
      "epoch 32 | loss: 0.39957 | train_auc: 0.79642 | val_auc: 0.84571 |  0:00:03s\n",
      "epoch 33 | loss: 0.40401 | train_auc: 0.78846 | val_auc: 0.83115 |  0:00:03s\n",
      "epoch 34 | loss: 0.40269 | train_auc: 0.79091 | val_auc: 0.833   |  0:00:03s\n",
      "epoch 35 | loss: 0.41741 | train_auc: 0.79231 | val_auc: 0.85538 |  0:00:03s\n",
      "epoch 36 | loss: 0.39049 | train_auc: 0.79366 | val_auc: 0.84912 |  0:00:03s\n",
      "epoch 37 | loss: 0.39523 | train_auc: 0.79643 | val_auc: 0.83908 |  0:00:04s\n",
      "epoch 38 | loss: 0.39584 | train_auc: 0.79966 | val_auc: 0.8434  |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_auc = 0.86579\n",
      "Best weights from best epoch are automatically used!\n",
      "Device used : cpu\n",
      "epoch 0  | loss: 0.87122 | train_auc: 0.42094 | val_auc: 0.4629  |  0:00:00s\n",
      "epoch 1  | loss: 0.66289 | train_auc: 0.4932  | val_auc: 0.52162 |  0:00:00s\n",
      "epoch 2  | loss: 0.59847 | train_auc: 0.5113  | val_auc: 0.52365 |  0:00:00s\n",
      "epoch 3  | loss: 0.6018  | train_auc: 0.50619 | val_auc: 0.51459 |  0:00:00s\n",
      "epoch 4  | loss: 0.59415 | train_auc: 0.5188  | val_auc: 0.57261 |  0:00:00s\n",
      "epoch 5  | loss: 0.57296 | train_auc: 0.54706 | val_auc: 0.61006 |  0:00:00s\n",
      "epoch 6  | loss: 0.56533 | train_auc: 0.52974 | val_auc: 0.60135 |  0:00:00s\n",
      "epoch 7  | loss: 0.53673 | train_auc: 0.53783 | val_auc: 0.61568 |  0:00:00s\n",
      "epoch 8  | loss: 0.51542 | train_auc: 0.60905 | val_auc: 0.62764 |  0:00:01s\n",
      "epoch 9  | loss: 0.51217 | train_auc: 0.63175 | val_auc: 0.60513 |  0:00:01s\n",
      "epoch 10 | loss: 0.51125 | train_auc: 0.6743  | val_auc: 0.61682 |  0:00:01s\n",
      "epoch 11 | loss: 0.49069 | train_auc: 0.69215 | val_auc: 0.63599 |  0:00:01s\n",
      "epoch 12 | loss: 0.53052 | train_auc: 0.71202 | val_auc: 0.62896 |  0:00:01s\n",
      "epoch 13 | loss: 0.51531 | train_auc: 0.71656 | val_auc: 0.60865 |  0:00:01s\n",
      "epoch 14 | loss: 0.49039 | train_auc: 0.72611 | val_auc: 0.63959 |  0:00:01s\n",
      "epoch 15 | loss: 0.47075 | train_auc: 0.73311 | val_auc: 0.67414 |  0:00:01s\n",
      "epoch 16 | loss: 0.47824 | train_auc: 0.73266 | val_auc: 0.67853 |  0:00:01s\n",
      "epoch 17 | loss: 0.49719 | train_auc: 0.73195 | val_auc: 0.66675 |  0:00:02s\n",
      "epoch 18 | loss: 0.45797 | train_auc: 0.74786 | val_auc: 0.67695 |  0:00:02s\n",
      "epoch 19 | loss: 0.47656 | train_auc: 0.76737 | val_auc: 0.67071 |  0:00:02s\n",
      "epoch 20 | loss: 0.4556  | train_auc: 0.76317 | val_auc: 0.68143 |  0:00:02s\n",
      "epoch 21 | loss: 0.45905 | train_auc: 0.76363 | val_auc: 0.70622 |  0:00:02s\n",
      "epoch 22 | loss: 0.44608 | train_auc: 0.75888 | val_auc: 0.72802 |  0:00:02s\n",
      "epoch 23 | loss: 0.44694 | train_auc: 0.75568 | val_auc: 0.71607 |  0:00:02s\n",
      "epoch 24 | loss: 0.44192 | train_auc: 0.75187 | val_auc: 0.7166  |  0:00:02s\n",
      "epoch 25 | loss: 0.44176 | train_auc: 0.74377 | val_auc: 0.71027 |  0:00:02s\n",
      "epoch 26 | loss: 0.43851 | train_auc: 0.74461 | val_auc: 0.70025 |  0:00:02s\n",
      "epoch 27 | loss: 0.41886 | train_auc: 0.74417 | val_auc: 0.70482 |  0:00:03s\n",
      "epoch 28 | loss: 0.41177 | train_auc: 0.74235 | val_auc: 0.6839  |  0:00:03s\n",
      "epoch 29 | loss: 0.40399 | train_auc: 0.74355 | val_auc: 0.69954 |  0:00:03s\n",
      "epoch 30 | loss: 0.42373 | train_auc: 0.7543  | val_auc: 0.71501 |  0:00:03s\n",
      "epoch 31 | loss: 0.39474 | train_auc: 0.77541 | val_auc: 0.71396 |  0:00:03s\n",
      "epoch 32 | loss: 0.43221 | train_auc: 0.78088 | val_auc: 0.70218 |  0:00:03s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_auc = 0.72802\n",
      "Best weights from best epoch are automatically used!\n",
      "Device used : cpu\n",
      "epoch 0  | loss: 0.89115 | train_auc: 0.60011 | val_auc: 0.50938 |  0:00:00s\n",
      "epoch 1  | loss: 0.6637  | train_auc: 0.59615 | val_auc: 0.61436 |  0:00:00s\n",
      "epoch 2  | loss: 0.62113 | train_auc: 0.61394 | val_auc: 0.65152 |  0:00:00s\n",
      "epoch 3  | loss: 0.59513 | train_auc: 0.64749 | val_auc: 0.69589 |  0:00:00s\n",
      "epoch 4  | loss: 0.60377 | train_auc: 0.66882 | val_auc: 0.72619 |  0:00:00s\n",
      "epoch 5  | loss: 0.60529 | train_auc: 0.72077 | val_auc: 0.75902 |  0:00:00s\n",
      "epoch 6  | loss: 0.58364 | train_auc: 0.73234 | val_auc: 0.78761 |  0:00:00s\n",
      "epoch 7  | loss: 0.58025 | train_auc: 0.75315 | val_auc: 0.80105 |  0:00:00s\n",
      "epoch 8  | loss: 0.57266 | train_auc: 0.75043 | val_auc: 0.81674 |  0:00:00s\n",
      "epoch 9  | loss: 0.54347 | train_auc: 0.73726 | val_auc: 0.81457 |  0:00:01s\n",
      "epoch 10 | loss: 0.54235 | train_auc: 0.71382 | val_auc: 0.78202 |  0:00:01s\n",
      "epoch 11 | loss: 0.54165 | train_auc: 0.74283 | val_auc: 0.74639 |  0:00:01s\n",
      "epoch 12 | loss: 0.52707 | train_auc: 0.75421 | val_auc: 0.73819 |  0:00:01s\n",
      "epoch 13 | loss: 0.50232 | train_auc: 0.74433 | val_auc: 0.71528 |  0:00:01s\n",
      "epoch 14 | loss: 0.48976 | train_auc: 0.74599 | val_auc: 0.72628 |  0:00:01s\n",
      "epoch 15 | loss: 0.47926 | train_auc: 0.7362  | val_auc: 0.73268 |  0:00:01s\n",
      "epoch 16 | loss: 0.48818 | train_auc: 0.74171 | val_auc: 0.74008 |  0:00:01s\n",
      "epoch 17 | loss: 0.48715 | train_auc: 0.73688 | val_auc: 0.74982 |  0:00:01s\n",
      "epoch 18 | loss: 0.48649 | train_auc: 0.72907 | val_auc: 0.72998 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_auc = 0.81674\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "from argparse import ArgumentParser, Namespace\n",
    "\n",
    "RANDOM_STATE = hash(\"fuck yeah!\") % (2 ** 32 - 1)\n",
    "print(RANDOM_STATE)\n",
    "\n",
    "\n",
    "train_path = osp.join('../data/processed/', \"train.csv\")\n",
    "train_df = pd.read_csv(train_path, index_col=\"PassengerId\")\n",
    "y = train_df[\"survived\"].values\n",
    "X = train_df.drop([\"survived\"], axis=1).values\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "val_mean_aucs = []\n",
    "train_mean_aucs = []\n",
    "best_epochs = []\n",
    "best_model = None\n",
    "best_val_auc = 0\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_val = X[train_index], X[test_index]\n",
    "    y_train, y_val = y[train_index], y[test_index]\n",
    "    model = TabNetClassifier(\n",
    "        seed=RANDOM_STATE,\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train, y_train, \n",
    "        eval_set=[(X_train, y_train), (X_val, y_val)], \n",
    "        eval_name=['train', 'val'],\n",
    "    )\n",
    "    valpreds = model.predict_proba(X_val)[:, 1]\n",
    "    trainpreds = model.predict_proba(X_train)[:, 1]\n",
    "    \n",
    "    val_auc = roc_auc_score(y_val, valpreds)\n",
    "    train_auc = roc_auc_score(y_train, trainpreds)\n",
    "    \n",
    "    if val_auc > best_val_auc:\n",
    "        best_model = model\n",
    "        best_val_auc = val_auc\n",
    "    \n",
    "    val_mean_aucs.append(val_auc)\n",
    "    train_mean_aucs.append(train_auc)\n",
    "    best_epochs.append(model.best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 15 |Â train AUC 0.7640485420529244 | val AUC 0.7896739130434784\n",
      "Best epoch: 20 |Â train AUC 0.7421988918051909 | val AUC 0.6693078324225865\n",
      "Best epoch: 28 |Â train AUC 0.8093996239255014 | val AUC 0.8657885040530583\n",
      "Best epoch: 22 |Â train AUC 0.7588784303026168 | val AUC 0.7280239099859352\n",
      "Best epoch: 8 |Â train AUC 0.7504327982373309 | val AUC 0.8167388167388168\n"
     ]
    }
   ],
   "source": [
    "train_mean_aucs = np.array(train_mean_aucs)\n",
    "val_mean_aucs = np.array(val_mean_aucs)\n",
    "best_epochs = np.array(best_epochs)\n",
    "\n",
    "for be, t, v in zip(best_epochs, train_mean_aucs, val_mean_aucs):\n",
    "    print(f\"Best epoch: {be} |Â train AUC {t} | val AUC {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7649916572647129\n",
      "0.7739065952487751\n"
     ]
    }
   ],
   "source": [
    "print(train_mean_aucs.mean())\n",
    "print(val_mean_aucs.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.8205845301083395\n",
      "0.10058495\n"
     ]
    }
   ],
   "source": [
    "preds = best_model.predict_proba(X)[:, 1]\n",
    "auc = roc_auc_score(y, preds)\n",
    "print(f\"AUC = {auc}\")\n",
    "fpr, tpr, thr = roc_curve(y, preds)\n",
    "optimial_thr = thr[np.argmax(tpr - fpr)]\n",
    "print(optimial_thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7632275132275133"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = (preds > optimial_thr).astype(int)\n",
    "(y_hat == y).sum() / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model at best_model_train_auc=82.zip\n",
      "Device used : cpu\n",
      "Device used : cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TabNetClassifier(n_d=8, n_a=8, n_steps=3, gamma=1.3, cat_idxs=[], cat_dims=[], cat_emb_dim=1, n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.02, lambda_sparse=0.001, seed=534413108, clip_value=1, verbose=1, optimizer_fn=<class 'torch.optim.adam.Adam'>, optimizer_params={'lr': 0.02}, scheduler_fn=None, scheduler_params={}, mask_type='sparsemax', input_dim=9, output_dim=2, device_name='auto')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'best_model_train_auc=82'\n",
    "best_model.save_model(name)\n",
    "loaded_model = TabNetClassifier()\n",
    "loaded_model.load_model(f\"{name}.zip\")\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(osp.join('../data/processed/', \"test.csv\"), index_col=\"PassengerId\")\n",
    "X_test = test_df.values\n",
    "probs = loaded_model.predict_proba(X_test)[:, 1]\n",
    "y_hat = (probs > optimial_thr).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data={\n",
    "        'y_pred': y_hat,\n",
    "    },\n",
    "    index=test_df.index\n",
    ").to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "698487d03f837c12ed9acd7a246542becdf3fe66990446d81ee4bf24aeef78ab"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('titanic': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
